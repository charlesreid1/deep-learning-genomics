{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/charlesreid1/deep-learning-genomics/blob/master/ray_tune_cnn1d_dna_transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JHAuCkB-Dyvx"
   },
   "source": [
    "# Hyperparameter Tuning with Ray, Tune, Keras, and Sklearn for Deep Learning Genomics\n",
    "\n",
    "In this notebook, we use keras to assemble a 1D convolutional neural network for a deep learning application in genomics, and tune the network hyperparameters (parameters related to the network architecture and training algorithm) using sklearn.\n",
    "\n",
    "In prior notebooks, we trained models and came to a better understanding of them using various metrics and plots. In this notebook, we re-use the figures and analysis from prior notebooks to help summarize a larger set of models, without as much of an explanation of how we arrived at those figures or how to interpret them. For more on that, see prior notebooks in the [charlesreid1/deep-learning-genomics](https://github.com/charlesreid1/deep-learning-genomics) repository on Github.\n",
    "\n",
    "This notebook will use a framework called [tune](https://ray.readthedocs.io/en/latest/tune.html), part of the [ray](http://github.com/ray-project/ray) framework. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAl5v_fEEz8Y"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62b9p_xalIIH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4gsmsa71Dv1k"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fhj_7ZaEPij"
   },
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VN-bDjOlEQDB"
   },
   "outputs": [],
   "source": [
    "# keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Embedding, Dense, Dropout, Input, Concatenate\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.layers import LeakyReLU\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ray &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "from ray.tune import Trainable\n",
    "from ray.tune.util import pin_in_object_store, get_pinned_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHkVmJYCEZfT"
   },
   "outputs": [],
   "source": [
    "seed = 1729\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZeBqpoaQcPvk"
   },
   "source": [
    "## Define Useful Keras Metrics\n",
    "\n",
    "Before we get started assembling our model, we define a few useful metric functions to use with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpthrvB3cST3"
   },
   "outputs": [],
   "source": [
    "# via https://github.com/keras-team/keras/issues/6507#issuecomment-322857357\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    # Calculate the precision\n",
    "    # clip ensures we're between 0 and 1\n",
    "    # round ensures we're either 0 or 1\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculate the recall\n",
    "    # clip ensures we're between 0 and 1\n",
    "    # round ensures we're either 0 or 1\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fvalue(y_true, y_pred):\n",
    "    # Calculate the F-value\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "    p = precision(y_true,y_pred)\n",
    "    r = recall(y_true,y_pred)\n",
    "    fvalue = (2 * p * r)/(p + r + K.epsilon())\n",
    "    return fvalue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yf8K8vRzEx3q"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "nxrwVCIBEsNJ",
    "outputId": "3ab8d67f-0e2d-427d-d449-ce7b1f8f17a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'DeepLearningLifeSciences' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/deepchem/DeepLearningLifeSciences.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEUJnDsbEtQa"
   },
   "outputs": [],
   "source": [
    "!ln -fs DeepLearningLifeSciences/Chapter06/{test*,train*,valid*} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPileDhWZyu5"
   },
   "outputs": [],
   "source": [
    "!ln -fs DeepLearningLifeSciences/Chapter06/chromatin.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4svZCHZZ5Wn"
   },
   "source": [
    "In contrast to the prior example, which uses the already-provided splits of training, testing, and validation, we will load all of the data all at once into a single X and y pair and use sklearn to split the data into testing and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "nSLjlrPBSiP_",
    "outputId": "ed3b241f-7e4c-4f96-dc86-6de3fbc4657f"
   },
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    \n",
    "    # load chromatin accessibility data\n",
    "    accessibility = {}\n",
    "    for line in open('chromatin.txt','r'):\n",
    "        fields = line.split()\n",
    "        accessibility[fields[0]] = float(fields[1])\n",
    "    \n",
    "    # load training, validation, and testing sets\n",
    "    for i,label in enumerate(['train','valid','test']):\n",
    "        datadir = \"%s_dataset\"%(label)\n",
    "        base_filename = \"shard-0-%s.joblib\"\n",
    "        X_filename = os.path.join(datadir,base_filename%(\"X\"))\n",
    "        y_filename = os.path.join(datadir,base_filename%(\"y\"))\n",
    "        ids_filename = os.path.join(datadir,base_filename%(\"ids\"))\n",
    "        \n",
    "        this_X = joblib.load(X_filename)\n",
    "        this_y = joblib.load(y_filename)\n",
    "        this_ids = joblib.load(ids_filename)\n",
    "        this_chromatin = np.array([accessibility[k] for k in this_ids])\n",
    "        \n",
    "        # add X and chromatin data\n",
    "        if i>0:\n",
    "            X = np.concatenate([X,this_X])\n",
    "            chromatin = np.concatenate([chromatin,this_chromatin])\n",
    "            y = np.concatenate([y,this_y])\n",
    "        else:\n",
    "            X = this_X\n",
    "            chromatin = this_chromatin\n",
    "            y = this_y\n",
    "        \n",
    "    return [X,chromatin], y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCvk_-iu2Vqq"
   },
   "source": [
    "# Parameter Tuning\n",
    "\n",
    "In the sections that follow, we assemble a keras 1D CNN and tune parameters of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9w1P_mjQPg56"
   },
   "source": [
    "## Using tune to tune hyperparameters\n",
    "\n",
    "To use [tune](https://ray.readthedocs.io/en/latest/tune.html) to tune model hyperparameters, we will use the [tutorial on using tune with keras](https://github.com/ray-project/tutorial/blob/master/tune_exercises/Tutorial.ipynb) as a guide.\n",
    "\n",
    "tune is installed as a component in [ray](https://github.com/ray-project/ray)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44RNErEgveih"
   },
   "source": [
    "## Parameter Exploration Plan\n",
    "\n",
    "At this point, we are ready to assemble the model. We should decide what parameters to adjust before assembling the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajOlBuGN7zhW"
   },
   "source": [
    "### Parameters that can be adjusted\n",
    "\n",
    "* The number of stacked convolutional layers (3 in the original version of the problem)\n",
    "* The number of filters in the convolution layers (16 in the original version of the problem)\n",
    "* The convolution window size (10 in the original version of the problem)\n",
    "* The dropout ratio for the dropout layers following the convolutional layers (0.5 originally)\n",
    "* The sequence length we feed into the neural net (101 originally)\n",
    "* Activation function used by the convolutional layers (RELU originally)\n",
    "* Activation function used by final binary classifier output (sigmoid originally)\n",
    "* Loss function (`binary_crossentropy` originally)\n",
    "* Optimizer (`adam` originally)\n",
    "\n",
    "### Parameters that we will adjust\n",
    "\n",
    "Because models are expensive to train, and we must train one model from scratch for _each_ unique parameter combination, we want to start with parameters that we think will have the largest impact (the parameters the model's correctness is most sensitive to).\n",
    "\n",
    "We list the three parameters that we will adjust below, with justification:\n",
    "\n",
    "* **Number of stacked convolutional layers** - more layers means we have a higher potential to extract features at the given layer of resolution, so adding more layers can uncover more structure in the 1D DNA sequences\n",
    "\n",
    "* **Number of filters in each convolutional layer** - more filters means more parts of the image are covered by more filters, making more likely that features will be extracted; adding more filters can reveal structures across more scales of the sequence; typically convolutional neural networks start with a small number of filters and cascade into more as the network gets deeper, so we explore a network that has increasing numbers of filters in each convolutional layer, and a network that has a fixed number of filters at each convolutional layer.\n",
    "\n",
    "* **Convolution window size** - a larger convolution window size means we are able to examine more of the sequence _simultaneously_, meaning we are more likely to find non-local effects among features in our sequence\n",
    "\n",
    "Why not simply crank up all the parameter values? Simpler networks have fewer parameters; as the network complexity increases, the need for data can explode. There is also a risk of overfitting the training data due to having too many parameters, and performing poorly on the general problem, so we want to try both simple and complex models.\n",
    "\n",
    "### Parameter values\n",
    "\n",
    "The initial hyperparameter study will search a three-parameter space, trying two values for each parameter. Our goal with this notebook is to demonstrate how to utilize hyperas, so we keep the search simple and limited in scope.\n",
    "\n",
    "* Number of stacked convolutional layers: \\[3, 4\\]\n",
    "\n",
    "* Number of convolutional filters at each layer (single filter size or doubling filter size):\n",
    "    * 3 convolutional layers: \\[16/16/16, 16/32/64\\]\n",
    "    * 4 convolutional layers: \\[16/16/16/16, 16/32/64/128\\]\n",
    "\n",
    "* Convolution window size: \\[10, 20\\]\n",
    "\n",
    "We are running $2^3 = 8$ cases:\n",
    "\n",
    "| Case | No. Stacked Conv1D Layers | No. Conv1D Filters | Conv1D Window Size |\n",
    "|------|---------------------------|--------------------|--------------------|\n",
    "| 1*  | 3                           | 16/16/16     | 10                |\n",
    "| 2    | 3                           | 16/16/16     | 25                |\n",
    "| 3    | 3                           | 16/32/64     | 10                |\n",
    "| 4    | 3                           | 16/32/64     | 25                |\n",
    "| 5    | 4                           | 16/16/16/16     | 10                |\n",
    "| 6    | 4                           | 16/16/16/16     | 20                |\n",
    "| 7    | 4                           | 16/32/64/128    | 10                |\n",
    "| 8    | 4                           | 16/32/64/128    | 20                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "3AlIqUjvvd14",
    "outputId": "1b431cc4-1557-48ca-9ecb-86381b5dcf01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, '16/16/...', 10),\n",
      " (3, '16/16/...', 20),\n",
      " (3, '16/32/...', 10),\n",
      " (3, '16/32/...', 20),\n",
      " (4, '16/16/...', 10),\n",
      " (4, '16/16/...', 20),\n",
      " (4, '16/32/...', 10),\n",
      " (4, '16/32/...', 20)]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from pprint import pprint\n",
    "\n",
    "hyperparam_combos = list(itertools.product([3,4],[\"16/16/...\",\"16/32/...\"],[10,20]))\n",
    "pprint(hyperparam_combos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4xfHFUbLN1Yu"
   },
   "source": [
    "To create a model that hyperas can call with the different parameter combinations, we will insert special calls to hyperas to tell it which parameter values to insert at different points in the function that creates the keras model. This will allow hyperas to create different models with different parameters or architectures, and to bake complex logic into the variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Trainable\n",
    "\n",
    "Now we are ready to create a function to help automate the hyperparameter search.\n",
    "\n",
    "The hyperparameter search will take place as a series of trials. Each trial runs a Python function called a trainable.\n",
    "\n",
    "The trainable function must:\n",
    "\n",
    "- pass in a tune_reporter object as a parameter: `def my_trainable(config, tune_reporter)`\n",
    "- train the model using the given parameters\n",
    "- report metrics to tune (so it can keep track of the model's performance over time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating with Keras via Keras Callback\n",
    "\n",
    "To integrate tune with keras, you can use a custom keras callback class, `TuneCallback`, which will report metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneCallback(keras.callbacks.Callback):\n",
    "    \"\"\"Custom Callback for Tune.\"\"\"\n",
    "\n",
    "    def __init__(self, reporter):\n",
    "        super(TuneCallback, self).__init__()\n",
    "        self.reporter = reporter\n",
    "        self.metrics = ['acc','precision','recall','fvalue']\n",
    "        self.most_important_metric = 'precision'\n",
    "        \n",
    "        # Top score for each metric\n",
    "        self.top = {}\n",
    "        for m in self.metrics:\n",
    "            self.top[m] = -1\n",
    "        \n",
    "        # Last 10 scores for each metric\n",
    "        self.last_10 = {}\n",
    "        for m in self.metrics:\n",
    "            self.last_10[m] = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        \"\"\"Reports the last result\"\"\"\n",
    "        curr = logs[self.most_important_metric]\n",
    "        top = self.top[self.most_important_metric]\n",
    "        \n",
    "        if curr > top:\n",
    "            self.model.save_weights('weights_tune_tmp.h5')\n",
    "            os.rename('weights_tune_tmp.h5','weights_tune.h5')\n",
    "        \n",
    "        reporter_kwargs = {}\n",
    "        \n",
    "        # For each metric we've defined (top of notebook),\n",
    "        # we want to keep track of the moving average\n",
    "        for m in self.metrics:\n",
    "            \n",
    "            # Drop oldest value\n",
    "            if len(self.last_10[m]) >= 5:\n",
    "                self.last_10[m] = self.last_10[m][1:]\n",
    "                \n",
    "            # Append newest value\n",
    "            self.last_10[m] = self.last_10[m] + [logs[m]]\n",
    "            \n",
    "            # Get name for mean metric\n",
    "            mean_metric = 'mean_' + m\n",
    "            \n",
    "            # Report mean of last 10 values of this metric\n",
    "            reporter_kwargs[mean_metric] = np.mean(self.last_10[m])\n",
    "        \n",
    "        reporter_kwargs['checkpoint'] = 'weights_tune.h5'\n",
    "        \n",
    "        self.reporter(**reporter_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Trainable Function\n",
    "\n",
    "The trainable function must:\n",
    "\n",
    "- pass in a tune_reporter object as a parameter: `def my_trainable(config, tune_reporter)`\n",
    "- train the model using the given parameters\n",
    "- report metrics to tune (so it can keep track of the model's performance over time)\n",
    "\n",
    "We split the trainable into two functions: \n",
    "\n",
    "* The first function `keras_chromastin_model()` assembles and returns uncompiled keras neural network with user-specified architecture parameters\n",
    "\n",
    "* The second function `tune_cnn_trainable(config, tune_reporter)` is the trainable function that is actually called by tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKTxabUHuCSX"
   },
   "outputs": [],
   "source": [
    "# This function is called from the trainable function.\n",
    "# The trainable function gets the hyperparameters specified\n",
    "# in the input dictionary (and picked by tune), and uses them\n",
    "# to call this function to assemble the keras CNN model.\n",
    "\n",
    "def keras_chromatin_model(n_convolutional_layers, n_convolutional_filters, convolution_window, seq_length, n_features):\n",
    "    \"\"\"\n",
    "    This function takes network architecture parameters as inputs,\n",
    "    and returns an uncompiled keras 1D convolutional neural network\n",
    "    with the specified architecture.\n",
    "    \"\"\"\n",
    "    # ----------------------------\n",
    "    # Sequence branch of network\n",
    "    # (1D DNA sequence)\n",
    "    \n",
    "    # Input\n",
    "    seq_in = Input(shape=(seq_length,n_features))\n",
    "    \n",
    "    # Fencepost pattern\n",
    "    seq = seq_in\n",
    "    \n",
    "    for i in range(n_convolutional_layers):\n",
    "        seq = Conv1D(n_convolutional_filters[i], \n",
    "                     convolution_window,\n",
    "                     activation='relu', \n",
    "                     padding='same',\n",
    "                     kernel_initializer='normal')(seq)\n",
    "        seq = Dropout(0.5)(seq)\n",
    "    \n",
    "    # Flatten to 1D\n",
    "    seq = Flatten()(seq)\n",
    "    \n",
    "    # Assemble the sequential branch of network\n",
    "    seq = keras.Model(inputs=seq_in, outputs=seq)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Chromatin branch of network\n",
    "    \n",
    "    # Input\n",
    "    chrom_input = Input(shape=(1,))\n",
    "\n",
    "    # ---------------------------\n",
    "    # Combine networks\n",
    "    fin = keras.layers.concatenate([seq.output, chrom_input])\n",
    "    fin = Dense(1,\n",
    "                activation='sigmoid', \n",
    "                kernel_initializer='normal')(fin)\n",
    "    chrom_model = keras.Model(inputs=[seq.input,chrom_input], \n",
    "                              outputs=fin)\n",
    "\n",
    "    return chrom_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiently Handling Large Data Sets\n",
    "\n",
    "To efficiently handle a large data set, we can load it once and pin it in memory using the tune object store. This is particularly convenient when the data lives in a file, as ray workers may not all have access to files on disk.\n",
    "\n",
    "We pin objects using tune's `pin_object_in_store()` utility function, then retrieve it using the `get_pinned_object()` utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-10 17:00:26,297\tINFO node.py:497 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-06-10_17-00-26_296667_85233/logs.\n",
      "2019-06-10 17:00:26,411\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:61814 to respond...\n",
      "2019-06-10 17:00:26,539\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:47608 to respond...\n",
      "2019-06-10 17:00:26,544\tINFO services.py:806 -- Starting Redis shard with 1.72 GB max memory.\n",
      "2019-06-10 17:00:26,592\tINFO node.py:511 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-06-10_17-00-26_296667_85233/logs.\n",
      "2019-06-10 17:00:26,598\tINFO services.py:1441 -- Starting the Plasma object store with 2.58 GB memory using /tmp.\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown(); ray.init(ignore_reinit_error=True)\n",
    "\n",
    "[X_temp,chromatin_temp], y_temp = load_all_data()\n",
    "X_ = pin_in_object_store(X_temp)\n",
    "chromatin_ = pin_in_object_store(chromatin_temp)\n",
    "y_ = pin_in_object_store(y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Trainable Function\n",
    "\n",
    "The next step is to define the trainable function - this is the function that is repeatedly called by tune during the process of optimizing and searching hyperparamter space.\n",
    "\n",
    "It takes two arguments as input - a config dictionary (containing the hyperparameter values that tune is passing to the model), and a tune reporter, which we use to connect the function caller (tune) with the function being called (the `train()` method of our keras model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DPpFMma4gXy"
   },
   "outputs": [],
   "source": [
    "def tune_cnn_trainable(config, tune_reporter):\n",
    "    \"\"\"\n",
    "    This function is a trainable function that is used by tune\n",
    "    to run the various hyperparameter configurations.\n",
    "    \n",
    "    This function should:\n",
    "    \n",
    "    - pass in a tune_reporter object as a parameter: def my_trainable(config, tune_reporter)\n",
    "    - train the model using the given parameters\n",
    "    - report metrics to tune (so it can keep track of the model's performance over time)\n",
    "    \n",
    "    The input data X and y should come from a generator.\n",
    "    This trainable function should take care of creating\n",
    "    the model, creating the input data, using the input data\n",
    "    to train the model, and reporting metrics back.\n",
    "    \"\"\"\n",
    "    #############################################\n",
    "    # Problem-specific parameters\n",
    "    \n",
    "    # length of k-mer over which we're convoluting\n",
    "    seq_length = 101\n",
    "    \n",
    "    # length of DNA alphabet\n",
    "    n_features = 4\n",
    "    \n",
    "    # cross-validation settings\n",
    "    n_fold = 2\n",
    "    \n",
    "    # colors to associate with each fold\n",
    "    colors = ['dusty purple','dusty green']\n",
    "    fold_colors = [sns.xkcd_rgb[j] for j in colors]\n",
    "    \n",
    "    # network settings\n",
    "    n_epochs = 5\n",
    "    batch_size = 2048\n",
    "    \n",
    "    if tune_reporter is None:\n",
    "        # it's a smoke test\n",
    "        n_epochs = 1\n",
    "    \n",
    "    \n",
    "    ############################################\n",
    "    # Hyperparameter values come from config\n",
    "    \n",
    "    n_convolutional_layers = config.get(\"n_convolutional_layers\",3)\n",
    "    convolutional_filters_mode = config.get(\"convolutional_filters_mode\",16)\n",
    "    convolutional_window = config.get(\"convolutional_window\",10)\n",
    "    \n",
    "    unique_param_string = \"layers%d_filtermode%d_window%d\"%(\n",
    "            n_convolutional_layers,\n",
    "            convolutional_filters_mode,\n",
    "            convolutional_window\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    # Construct network\n",
    "    \n",
    "    # if mode = 16, use all 16s for every layer\n",
    "    # if mode = 32, double each layer until 64\n",
    "    n_convolutional_filters = None\n",
    "    if convolutional_filters_mode==16:\n",
    "        if n_convolutional_layers==3:\n",
    "            n_convolutional_filters = [16,16,16]\n",
    "        elif n_convolutional_layers==4:\n",
    "            n_convolutional_filters = [16,16,16,16]\n",
    "            \n",
    "    elif convolutional_filters_mode==32:\n",
    "        if n_convolutional_layers==3:\n",
    "            n_convolutional_filters = [16,32,64]\n",
    "        elif n_convolutional_filters==4:\n",
    "            n_convolutional_filters = [16,32,64,64]\n",
    "\n",
    "    if n_convolutional_filters==None:\n",
    "        msg = \"Error: invalid number of filters per layer or number of layers, could not set number of filters for layers.\"\n",
    "        raise Exception(msg)\n",
    "\n",
    "    chrom_model = keras_chromatin_model(n_convolutional_layers, \n",
    "                                        n_convolutional_filters, \n",
    "                                        convolutional_window, \n",
    "                                        seq_length, \n",
    "                                        n_features)\n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    # Input data\n",
    "    \n",
    "    # Here, we need to load X and y\n",
    "    X = get_pinned_object(X_)\n",
    "    chromatin = get_pinned_object(chromatin_)\n",
    "    y = get_pinned_object(y_)\n",
    "\n",
    "    # stratified = ratios of classes are preserved in each fold\n",
    "    shuffle = StratifiedShuffleSplit(n_splits=n_fold,\n",
    "                                     train_size = 0.7,\n",
    "                                     test_size = 0.3,\n",
    "                                     random_state = seed)\n",
    "    \n",
    "    # ------------\n",
    "    # Begin cross-validation process\n",
    "    #\n",
    "    # Iterate over each of the k-fold training/testing splits\n",
    "    # and create and train a model from scratch. Save the\n",
    "    # training history, then return the model and its history.\n",
    "    \n",
    "    for ifold, (train_ix, test_ix) in enumerate(shuffle.split(X,y)):\n",
    "        \n",
    "        #############################################\n",
    "        # Model training\n",
    "        \n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        chrom_train, chrom_test = chromatin[train_ix], chromatin[test_ix]\n",
    "\n",
    "        # ---------------------------\n",
    "        # Assemble class weights \n",
    "        # from the training data only\n",
    "        # (no peeking at the test data!)\n",
    "        classes = np.unique(y_train)\n",
    "        labels = np.squeeze(y_train)\n",
    "        weights = class_weight.compute_class_weight('balanced',classes,labels)\n",
    "        class_weights = {}\n",
    "        for c,w in zip(classes,weights):\n",
    "            class_weights[c] = w\n",
    "        \n",
    "        # Compile the model\n",
    "        chrom_model.compile(loss='binary_crossentropy',\n",
    "                       optimizer='adam',\n",
    "                       metrics=['accuracy',\n",
    "                               precision,\n",
    "                               recall,\n",
    "                               fvalue])\n",
    "        \n",
    "        if tune_reporter is not None:\n",
    "            # This is for tune\n",
    "            callbacks = [TuneCallback(tune_reporter)]\n",
    "            verb = 0\n",
    "        else:\n",
    "            callbacks = []\n",
    "            verb = 1\n",
    "        \n",
    "        # Fit to data\n",
    "        hist = chrom_model.fit([X_train,chrom_train], y_train,\n",
    "                               batch_size = batch_size,\n",
    "                               epochs = n_epochs,\n",
    "                               class_weight = class_weights,\n",
    "                               verbose = verb,\n",
    "                               callbacks = callbacks,\n",
    "                               validation_data = ([X_test,chrom_test], y_test))\n",
    "        \n",
    "        #histories.append(hist)\n",
    "        #models.append(chrom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Reporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tune trainable has the following keyword args:\n",
      "dict_keys(['mean_acc', 'mean_precision', 'mean_recall', 'mean_fvalue', 'checkpoint'])\n",
      "\n",
      "Works!\n"
     ]
    }
   ],
   "source": [
    "class GoodError(Exception):\n",
    "    pass\n",
    "\n",
    "def test_reporter(tune_cnn_trainable):\n",
    "    def mock_reporter(**kwargs):\n",
    "        #assert \"mean_acc\" in kwargs, \"Did not report mean_accuracy metric\"\n",
    "        #assert \"checkpoint\" in kwargs, \"Accidentally removed `checkpoint`?\"\n",
    "        print(\"The tune trainable has the following keyword args:\")\n",
    "        print(kwargs.keys())\n",
    "        print()\n",
    "        raise GoodError(\"This works.\")\n",
    "    try:\n",
    "        tune_cnn_trainable({}, mock_reporter)\n",
    "    except TypeError as e:\n",
    "        print(\"Forgot to modify function signature?\")\n",
    "        raise e\n",
    "    except GoodError:\n",
    "        print(\"Works!\")\n",
    "        return 1\n",
    "    raise Exception(\"Didn't call reporter...\")\n",
    "\n",
    "assert test_reporter(tune_cnn_trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke test: make sure that when we call the above function,\n",
    "# we successfully create and train a model.\n",
    "# This will train k models (because k-fold cross validation).\n",
    "\n",
    "if False:\n",
    "    \n",
    "    tune_cnn_trainable({\n",
    "            'n_convolutional_layers':3,\n",
    "            'convolutional_filters_mode':16,\n",
    "            'convolutional_window':10\n",
    "        },None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop={\"training_iteration\": 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'n_convolutional_layers': tune.grid_search([3]),\n",
    "    'convolutional_filters_mode': tune.grid_search([16,32]),\n",
    "    'convolutional_window': tune.grid_search([10,25])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_slim = {\n",
    "    'n_convolutional_layers': tune.grid_search([3]),\n",
    "    'convolutional_filters_mode': tune.grid_search([16]),\n",
    "    'convolutional_window': tune.grid_search([10])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-10 17:01:02,260\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-06-10 17:01:02,262\tINFO tune.py:223 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.4/8.6 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.4/8.6 GB\n",
      "Result logdir: /Users/charles/ray_results/tune_cnn_trainable\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=85949)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=85949)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85949)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85949)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=85949)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85949)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85949)\u001b[0m Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "\u001b[2m\u001b[36m(pid=85949)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85949)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85949)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=85949)\u001b[0m 2019-06-10 17:01:09.899389: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.6/8.6 GB\n",
      "Result logdir: /Users/charles/ray_results/tune_cnn_trainable\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85949], 4 s, 1 iter\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-10 17:01:16,650\tINFO ray_trial_executor.py:180 -- Destroying actor for trial tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.7/8.6 GB\n",
      "Result logdir: /Users/charles/ray_results/tune_cnn_trainable\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3:\tTERMINATED, [1 CPUs, 0 GPUs], [pid=85949], 9 s, 10 iter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start with slim parameter space exploration (one parameter set)\n",
    "slim_trials = tune.run(\n",
    "    tune_cnn_trainable,\n",
    "    stop=stop, \n",
    "    config=space_slim,\n",
    "    resources_per_trial={\"cpu\": 1},\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ray.tune.trial.Trial'>\n",
      "\n",
      "['ERROR', 'PAUSED', 'PENDING', 'RUNNING', 'TERMINATED', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_checkpoint', '_cmp_greater', '_get_trainable_cls', '_nonjson_fields', '_registration_check', '_status_string', 'best_checkpoint_attr_value', 'best_result', 'checkpoint_at_end', 'checkpoint_freq', 'checkpoint_score_attr', 'clear_checkpoint', 'close_logger', 'compare_checkpoints', 'config', 'custom_trial_name', 'error_file', 'experiment_tag', 'export_formats', 'extra_arg', 'generate_id', 'has_checkpoint', 'history', 'init_logger', 'is_finished', 'keep_checkpoints_num', 'last_debug', 'last_result', 'last_update_time', 'local_dir', 'logdir', 'loggers', 'max_failures', 'num_failures', 'param_config', 'progress_string', 'resources', 'result_logger', 'results', 'runner', 'set_verbose', 'should_checkpoint', 'should_recover', 'should_stop', 'status', 'stopping_criterion', 'sync_function', 'sync_logger_to_new_location', 'trainable_name', 'trial_id', 'update_last_result', 'update_resources', 'upload_dir', 'verbose', 'write_error_log']\n",
      "\n",
      "[]\n",
      "\n",
      "{'mean_acc': 0.9130859375, 'mean_precision': 0.0, 'mean_recall': 0.0, 'mean_fvalue': 0.0, 'checkpoint': 'weights_tune.h5', 'time_this_iter_s': 0.5178539752960205, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 10, 'experiment_id': '71d6f458f83d4a97b02f228a0048a24d', 'date': '2019-06-10_17-01-16', 'timestamp': 1560211276, 'time_total_s': 9.676398754119873, 'pid': 85949, 'hostname': 'maya', 'node_ip': '127.0.0.1', 'config': {'n_convolutional_layers': 3, 'convolutional_filters_mode': 16, 'convolutional_window': 10}, 'time_since_restore': 9.676398754119873, 'timesteps_since_restore': 0, 'iterations_since_restore': 10}\n"
     ]
    }
   ],
   "source": [
    "print(type(slim_trials[0]))\n",
    "print()\n",
    "print(dir(slim_trials[0]))\n",
    "print()\n",
    "print(slim_trials[0].history)\n",
    "print()\n",
    "print(slim_trials[0].last_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-10 17:01:47,540\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-06-10 17:01:47,541\tINFO tune.py:223 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.6/8.6 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 1/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.6/8.6 GB\n",
      "Result logdir: /Users/charles/ray_results/tune_cnn_trainable\n",
      "Number of trials: 4 ({'RUNNING': 1, 'PENDING': 3})\n",
      "PENDING trials:\n",
      " - tune_cnn_trainable_1_convolutional_filters_mode=32,convolutional_window=10,n_convolutional_layers=3:\tPENDING\n",
      " - tune_cnn_trainable_2_convolutional_filters_mode=16,convolutional_window=25,n_convolutional_layers=3:\tPENDING\n",
      " - tune_cnn_trainable_3_convolutional_filters_mode=32,convolutional_window=25,n_convolutional_layers=3:\tPENDING\n",
      "RUNNING trials:\n",
      " - tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=85952)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=85950)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=85951)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=85982)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=85952)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85952)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85952)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=85950)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85950)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85950)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=85951)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85951)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85951)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=85951)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85951)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85951)\u001b[0m Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "\u001b[2m\u001b[36m(pid=85952)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85952)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85952)\u001b[0m Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "\u001b[2m\u001b[36m(pid=85950)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85950)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85950)\u001b[0m Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "\u001b[2m\u001b[36m(pid=85982)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85982)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85982)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=85982)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85982)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85982)\u001b[0m Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "\u001b[2m\u001b[36m(pid=85951)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85951)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85951)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=85952)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85952)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85952)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=85950)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85950)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85950)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=85982)\u001b[0m WARNING:tensorflow:From /Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=85982)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=85982)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=85951)\u001b[0m 2019-06-10 17:02:01.371896: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=85952)\u001b[0m 2019-06-10 17:02:01.466065: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=85950)\u001b[0m 2019-06-10 17:02:01.545027: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=85982)\u001b[0m 2019-06-10 17:02:01.711503: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.9/8.6 GB\n",
      "Result logdir: /Users/charles/ray_results/tune_cnn_trainable\n",
      "Number of trials: 4 ({'RUNNING': 4})\n",
      "RUNNING trials:\n",
      " - tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85950], 10 s, 1 iter\n",
      " - tune_cnn_trainable_1_convolutional_filters_mode=32,convolutional_window=10,n_convolutional_layers=3:\tRUNNING\n",
      " - tune_cnn_trainable_2_convolutional_filters_mode=16,convolutional_window=25,n_convolutional_layers=3:\tRUNNING\n",
      " - tune_cnn_trainable_3_convolutional_filters_mode=32,convolutional_window=25,n_convolutional_layers=3:\tRUNNING\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.9/8.6 GB\n",
      "Result logdir: /Users/charles/ray_results/tune_cnn_trainable\n",
      "Number of trials: 4 ({'RUNNING': 4})\n",
      "RUNNING trials:\n",
      " - tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85950], 15 s, 4 iter\n",
      " - tune_cnn_trainable_1_convolutional_filters_mode=32,convolutional_window=10,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85951], 12 s, 1 iter\n",
      " - tune_cnn_trainable_2_convolutional_filters_mode=16,convolutional_window=25,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85952], 16 s, 2 iter\n",
      " - tune_cnn_trainable_3_convolutional_filters_mode=32,convolutional_window=25,n_convolutional_layers=3:\tRUNNING\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.8/8.6 GB\n",
      "Result logdir: /Users/charles/ray_results/tune_cnn_trainable\n",
      "Number of trials: 4 ({'RUNNING': 4})\n",
      "RUNNING trials:\n",
      " - tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85950], 20 s, 7 iter\n",
      " - tune_cnn_trainable_1_convolutional_filters_mode=32,convolutional_window=10,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85951], 21 s, 3 iter\n",
      " - tune_cnn_trainable_2_convolutional_filters_mode=16,convolutional_window=25,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85952], 20 s, 3 iter\n",
      " - tune_cnn_trainable_3_convolutional_filters_mode=32,convolutional_window=25,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85982], 19 s, 1 iter\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-10 17:02:22,144\tINFO ray_trial_executor.py:180 -- Destroying actor for trial tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 7.0/8.6 GB\n",
      "Result logdir: /Users/charles/ray_results/tune_cnn_trainable\n",
      "Number of trials: 4 ({'RUNNING': 4})\n",
      "RUNNING trials:\n",
      " - tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85950], 25 s, 9 iter\n",
      " - tune_cnn_trainable_1_convolutional_filters_mode=32,convolutional_window=10,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85951], 26 s, 4 iter\n",
      " - tune_cnn_trainable_2_convolutional_filters_mode=16,convolutional_window=25,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85952], 25 s, 4 iter\n",
      " - tune_cnn_trainable_3_convolutional_filters_mode=32,convolutional_window=25,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85982], 19 s, 1 iter\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.7/8.6 GB\n",
      "Result logdir: /Users/charles/ray_results/tune_cnn_trainable\n",
      "Number of trials: 4 ({'TERMINATED': 1, 'RUNNING': 3})\n",
      "RUNNING trials:\n",
      " - tune_cnn_trainable_1_convolutional_filters_mode=32,convolutional_window=10,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85951], 31 s, 5 iter\n",
      " - tune_cnn_trainable_2_convolutional_filters_mode=16,convolutional_window=25,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85952], 33 s, 6 iter\n",
      " - tune_cnn_trainable_3_convolutional_filters_mode=32,convolutional_window=25,n_convolutional_layers=3:\tRUNNING, [1 CPUs, 0 GPUs], [pid=85982], 30 s, 2 iter\n",
      "TERMINATED trials:\n",
      " - tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3:\tTERMINATED, [1 CPUs, 0 GPUs], [pid=85950], 27 s, 10 iter\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread ray_print_logs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 185, in _read_from_socket\n",
      "    raise socket.error(SERVER_CLOSED_CONNECTION_ERROR)\n",
      "OSError: Connection closed by server.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ray/worker.py\", line 1554, in print_logs\n",
      "    msg = pubsub_client.get_message()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/client.py\", line 3135, in get_message\n",
      "    response = self.parse_response(block=False, timeout=timeout)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/client.py\", line 3036, in parse_response\n",
      "    return self._execute(connection, connection.read_response)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/client.py\", line 3013, in _execute\n",
      "    return command(*args)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 637, in read_response\n",
      "    response = self._parser.read_response()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 290, in read_response\n",
      "    response = self._buffer.readline()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 224, in readline\n",
      "    self._read_from_socket()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 199, in _read_from_socket\n",
      "    (e.args,))\n",
      "redis.exceptions.ConnectionError: Error while reading from socket: ('Connection closed by server.',)\n",
      "Exception in thread ray_import_thread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 185, in _read_from_socket\n",
      "    raise socket.error(SERVER_CLOSED_CONNECTION_ERROR)\n",
      "OSError: Connection closed by server.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ray/import_thread.py\", line 69, in _run\n",
      "    msg = import_pubsub_client.get_message()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/client.py\", line 3135, in get_message\n",
      "    response = self.parse_response(block=False, timeout=timeout)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/client.py\", line 3036, in parse_response\n",
      "    return self._execute(connection, connection.read_response)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/client.py\", line 3013, in _execute\n",
      "    return command(*args)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 637, in read_response\n",
      "    response = self._parser.read_response()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 290, in read_response\n",
      "    response = self._buffer.readline()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 224, in readline\n",
      "    self._read_from_socket()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 199, in _read_from_socket\n",
      "    (e.args,))\n",
      "redis.exceptions.ConnectionError: Error while reading from socket: ('Connection closed by server.',)\n",
      "\n",
      "\n",
      "Exception in thread ray_listen_error_messages:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 185, in _read_from_socket\n",
      "    raise socket.error(SERVER_CLOSED_CONNECTION_ERROR)\n",
      "OSError: Connection closed by server.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ray/worker.py\", line 1656, in listen_error_messages_raylet\n",
      "    msg = worker.error_message_pubsub_client.get_message()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/client.py\", line 3135, in get_message\n",
      "    response = self.parse_response(block=False, timeout=timeout)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/client.py\", line 3036, in parse_response\n",
      "    return self._execute(connection, connection.read_response)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/client.py\", line 3013, in _execute\n",
      "    return command(*args)\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 637, in read_response\n",
      "    response = self._parser.read_response()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 290, in read_response\n",
      "    response = self._buffer.readline()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 224, in readline\n",
      "    self._read_from_socket()\n",
      "  File \"/Users/charles/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/redis/connection.py\", line 199, in _read_from_socket\n",
      "    (e.args,))\n",
      "redis.exceptions.ConnectionError: Error while reading from socket: ('Connection closed by server.',)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_ids, num_returns, timeout)\u001b[0m\n\u001b[1;32m   2323\u001b[0m             \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2324\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2325\u001b[0m         )\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.RayletClient.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: [RayletClient] Raylet connection closed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-9991d6f5e75d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresources_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_function, checkpoint_freq, checkpoint_at_end, export_formats, max_failures, restore, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mlast_debug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_debug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mDEBUG_PRINT_INTERVAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-4.3.30/lib/python3.6/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_ids, num_returns, timeout)\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2323\u001b[0m             \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2324\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2325\u001b[0m         )\n\u001b[1;32m   2326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now explore the whole parameter space\n",
    "full_trials = tune.run(\n",
    "    tune_cnn_trainable,\n",
    "    stop=stop, \n",
    "    config=space,\n",
    "    resources_per_trial={\"cpu\": 1},\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = full_trials[0]\n",
    "\n",
    "print(t)\n",
    "print()\n",
    "print(type(t))\n",
    "print()\n",
    "print(dir(t))\n",
    "print()\n",
    "print(t.logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"/Users/charles/ray_results/tune_cnn_trainable/tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3_2019-06-09_14-45-29_pk90zjj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"/Users/charles/ray_results/tune_cnn_trainable/tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3_2019-06-09_14-45-29_pk90zjj/result.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# LOAD HISTORY FOR ONE RUN\n",
    "#\n",
    "# This is the dumb way to do it.\n",
    "# The smart way is to utuilize\n",
    "# the built-in functionality that\n",
    "# tune provides to you.\n",
    "# \n",
    "# https://ray.readthedocs.io/en/latest/tune-usage.html#logging-analyzing-and-visualizing-results\n",
    "#\n",
    "#####################################\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "history = []\n",
    "with open(\"/Users/charles/ray_results/tune_cnn_trainable/tune_cnn_trainable_0_convolutional_filters_mode=16,convolutional_window=10,n_convolutional_layers=3_2019-06-09_14-45-29_pk90zjj/result.json\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        # One dictionary per line\n",
    "        d = json.loads(line)\n",
    "        \n",
    "        # Flatten the (nested) config dictionary\n",
    "        temp = d['config']\n",
    "        del d['config']\n",
    "        for k in temp.keys():\n",
    "            d[k] = temp[k]\n",
    "        \n",
    "        #pprint(d)\n",
    "        history.append(d)\n",
    "\n",
    "df = pd.DataFrame(history)\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(12,4))\n",
    "\n",
    "df['mean_acc'].plot(ax=axes[0])\n",
    "df['mean_precision'].plot(ax=axes[1])\n",
    "\n",
    "axes[0].set_title('Mean Accuracy')\n",
    "axes[0].set_xlabel('Training Iteration')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "\n",
    "axes[1].set_title('Mean Precision')\n",
    "axes[1].set_xlabel('Training Iteration')\n",
    "axes[1].set_ylabel('Precision')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# THE EASY WAY\n",
    "#######################\n",
    "\n",
    "from ray.tune.analysis import ExperimentAnalysis\n",
    "\n",
    "ea = ExperimentAnalysis(\"~/ray_results/my_experiment\")\n",
    "trials_dataframe = ea.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFM0RGTBtjse"
   },
   "source": [
    "This is currently our stopping point.\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Post-process metrics\n",
    "\n",
    "'''\n",
    "We have multiple metrics for each model:\n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f1 score\n",
    "- all of above at each epoch\n",
    "\n",
    "Once we use each model to evaluate y_test, we can get:\n",
    "- confusion matrix\n",
    "- construct roc with confidence interval\n",
    "- roc_auc_score\n",
    "\n",
    "We can aggregate these metrics many ways, \n",
    "but for now we stick to using roc_auc_score.\n",
    "hyperas will use that to pick the best model.\n",
    "\n",
    "We should make the plots and save them to \n",
    "image files, then display the image files in\n",
    "notebook cells below when we analyze the results\n",
    "of the hyperparamter study.\n",
    "'''\n",
    "# ---------------------\n",
    "# Compute aggregate statistics\n",
    "# for each metric\n",
    "\n",
    "loss      = [h.history['val_loss'] for h in histories]\n",
    "loss_mean = np.mean(loss)\n",
    "loss_std  = np.std(loss)\n",
    "\n",
    "acc       = [h.history['val_acc'] for h in histories]\n",
    "acc_mean  = np.mean(acc)\n",
    "acc_std   = np.std(acc)\n",
    "\n",
    "prec      = [h.history['val_pprecision'] for h in histories]\n",
    "prec_mean = np.mean(prec)\n",
    "prec_std  = np.std(prec)\n",
    "\n",
    "rec       = [h.history['val_recall'] for h in histories]\n",
    "rec_mean  = np.mean(rec)\n",
    "rec_std   = np.std(rec)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Define functions to plot metric histories\n",
    "\n",
    "def loss_rate_plot(histories, ax, label='', legend=False):\n",
    "\n",
    "    for ih, hist in enumerate(histories):\n",
    "\n",
    "        ax.plot(hist.history['loss'], \n",
    "                label='Train Loss (%d)'%(ih+1),\n",
    "                color=fold_colors[ih],\n",
    "                linestyle='--')\n",
    "\n",
    "        ax.plot(hist.history['val_loss'], \n",
    "                label='Test Loss (%d)'%(ih+1),\n",
    "                color=fold_colors[ih],\n",
    "                linestyle='-')\n",
    "\n",
    "    if label=='':\n",
    "        ax.set_title(\"Loss\", size=14)\n",
    "    else:\n",
    "        ax.set_title(\"Loss (%s)\"%(label), size=14)\n",
    "\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_xlabel('Training epoch')\n",
    "\n",
    "    if legend:\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "def accuracy_rate_plot(histories, ax, label='', legend=False):\n",
    "\n",
    "    for ih, hist in enumerate(histories):\n",
    "\n",
    "        ax.plot([j*100 for j in hist.history['acc']],\n",
    "                label='Train Acc (%d)'%(ih+1),\n",
    "                color=fold_colors[ih],\n",
    "                linestyle='--')\n",
    "\n",
    "        ax.plot([j*100 for j in hist.history['val_acc']],\n",
    "                label='Test Acc (%d)'%(ih+1),\n",
    "                color=fold_colors[ih],\n",
    "                linestyle='-')\n",
    "\n",
    "    if label=='':\n",
    "        ax.set_title(\"Accuracy\", size=14)\n",
    "    else:\n",
    "        ax.set_title(\"Accuracy (%s)\"%(label), size=14)\n",
    "\n",
    "    ax.set_ylabel('Accuracy %')\n",
    "    ax.set_xlabel('Training epoch')\n",
    "\n",
    "    if legend:\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "def precision_rate_plot(histories, ax, label='', legend=False):\n",
    "\n",
    "    for ih, hist in enumerate(histories):\n",
    "\n",
    "        ax.plot([j*100 for j in hist.history['precision']],\n",
    "                label='Train Recall (%d)'%(ih+1),\n",
    "                color=fold_colors[ih],\n",
    "                linestyle='--')\n",
    "\n",
    "        ax.plot([j*100 for j in hist.history['val_precision']],\n",
    "                label='Test Recall (%d)'%(ih+1),\n",
    "                color=fold_colors[ih],\n",
    "                linestyle='-')\n",
    "\n",
    "    if label=='':\n",
    "        ax.set_title(\"Precision\", size=14)\n",
    "    else:\n",
    "        ax.set_title(\"Precision (%s)\"%(label), size=14)\n",
    "\n",
    "    ax.set_ylabel('Precision %')\n",
    "    ax.set_xlabel('Training epoch')\n",
    "\n",
    "    if legend:\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "def recall_rate_plot(histories, ax, label='', legend=False):\n",
    "\n",
    "    for ih, hist in enumerate(histories):\n",
    "\n",
    "        ax.plot([j*100 for j in hist.history['recall']],\n",
    "                label='Train Recall (%d)'%(ih+1),\n",
    "                color=fold_colors[ih],\n",
    "                linestyle='--')\n",
    "\n",
    "        ax.plot([j*100 for j in hist.history['val_recall']],\n",
    "                label='Test Recall (%d)'%(ih+1),\n",
    "                color=fold_colors[ih],\n",
    "                linestyle='--')\n",
    "\n",
    "    if label=='':\n",
    "        ax.set_title(\"Recall\", size=14)\n",
    "    else:\n",
    "        ax.set_title(\"Recall (%s)\"%(label), size=14)\n",
    "\n",
    "    ax.set_ylabel('Recall %')\n",
    "    ax.set_xlabel('Training epoch')\n",
    "\n",
    "    if legend:\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Define functions to make confusion matrix plot\n",
    "\n",
    "def plot_confusion_matrix(ax, y_true, y_pred, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    if title is None:\n",
    "        title = \"Confusion Matrix\"\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), \n",
    "             rotation=45,\n",
    "             ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else ','\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", \n",
    "                    va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "# ---------------------\n",
    "# Define functions to plot ROC curves\n",
    "\n",
    "def plot_roc_confidence(models, ax, X, chromatin, y, shuffle):\n",
    "    \"\"\"Plot the ROC curve with confidence interval on ax.\n",
    "    Return the mean and std of the ROC AUC, computed over\n",
    "    each of the k folds from cross-validation.\n",
    "    \"\"\"\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "\n",
    "    for ifold, (train_ix, test_ix) in enumerate(shuffle.split(X,y)):\n",
    "\n",
    "        print(\"Working on fold %d...\"%(ifold+1))\n",
    "\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        chrom_train, chrom_test = chromatin[train_ix], chromatin[test_ix]\n",
    "\n",
    "        model = models[ifold]\n",
    "\n",
    "        y_test_pred = model.predict([X_test,chrom_test]).ravel()\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "\n",
    "        tprs.append(interp(mean_fpr,fpr,tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr,tpr)\n",
    "        aucs.append(roc_auc)\n",
    "\n",
    "        # Draw every ROC curve, lightly\n",
    "        ax.plot(fpr,tpr, alpha=0.3)\n",
    "\n",
    "mean_tpr = np.mean(tprs,axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Draw the mean curve\n",
    "ax.plot(mean_fpr, mean_tpr, \n",
    "        color='b', alpha=0.8)\n",
    "\n",
    "# Now fill in the area between +/- std\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, \n",
    "                color='grey', alpha=0.2)\n",
    "\n",
    "# Diag for ref\n",
    "ax.plot([0,1],[0,1],'--k',lw=2)\n",
    "\n",
    "ax.set_title('ROC Curve, 1D CNN With Chromatin')\n",
    "\n",
    "return mean_auc, std_auc\n",
    "\n",
    "\n",
    "####################################\n",
    "# Make plots\n",
    "\n",
    "# ---------------------\n",
    "# Plot metric histories for all the folds\n",
    "# and save the plot to a file\n",
    "\n",
    "# 4 subplots for 4 metrics\n",
    "fig, [[ax1,ax2],[ax3,ax4]] = plt.subplots(2,2, figsize=(8,6))\n",
    "\n",
    "loss_rate_plot(fithists[i], ax1, legend=True)\n",
    "accuracy_rate_plot(fithists[i], ax2, legend=True)\n",
    "precision_rate_plot(fithists[i], ax3, legend=True)\n",
    "recall_rate_plot(fithists[i], ax4, legend=True)\n",
    "\n",
    "metric_histories_img = 'MetricHistories_%s.png'%(unique_param_string)\n",
    "print(\"Saving metric histories to %s\"%(metric_histories_img))\n",
    "fig.savefig(metric_histories_img)\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Plot confusion matrix \n",
    "# for all the folds for this model.\n",
    "# Save plots to files.\n",
    "\n",
    "cm_fig, cm_axes = plt.subplots(nrows=len(histories),ncols=1)\n",
    "roc_fig, roc_axes = plt.subplots()\n",
    "\n",
    "for ifold, (train_ix, test_ix) in enumerate(shuffle.split(X,y)):\n",
    "    hist = histories[ifold]\n",
    "    model = models[ifold]\n",
    "\n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    chrom_train, chrom_test = chromatin[train_ix], chromatin[test_ix]\n",
    "\n",
    "    y_test_pred = model.predict([X_test,chrom_test])\n",
    "    y_test_pred = np.round(y_test_pred)\n",
    "\n",
    "    # Confusion matrix plot\n",
    "    cm_title = \"Confusion Matrix (Fold %d)\"%(ifold+1)\n",
    "    cm_ax = cm_axes[ifold]        \n",
    "    plot_confusion_matrix(cm_ax,y_test,y_test_pred,title=cm_title)\n",
    "\n",
    "cm_img = 'ConfusionMatrix_%s.png'%(unique_param_string)\n",
    "print(\"Saving confusion matrices to %s\"%(cm_img))\n",
    "cm_fig.savefig(cm_img)\n",
    "\n",
    "# ---------------------\n",
    "# Plot ROC curve (and get ROC AUC)\n",
    "# for all the folds for this model.\n",
    "# Save plots to files.\n",
    "\n",
    "roc_fig, roc_ax = plt.subplots(1,1, figsize=(8,6))\n",
    "\n",
    "mean_auc, std_auc = plot_roc_confidence(models, roc_ax, X, chromatin, y, shuffle)\n",
    "\n",
    "roc_img = 'ROCConfidence_%s.png'%(unique_param_string)\n",
    "print('Saving ROC confidence curve to %s'%(roc_img))\n",
    "roc_fig.savefig(roc_img)\n",
    "\n",
    "print(\"Area under ROC curve:\")\n",
    "print(\"\\tMean: %0.4f\"%(mean_auc))\n",
    "print(\"\\tStd: %0.4f\"%(std_auc))\n",
    "\n",
    "# which model are we supposed to return?\n",
    "# can we return a list? \n",
    "# can we create an aggregate model that wraps all 3? \n",
    "\n",
    "return {'loss': mean_auc, 'status': STATUS_OK, 'model': models}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFM0RGTBtjse"
   },
   "source": [
    "## Performing Cross Validation Manually\n",
    "\n",
    "To perform cross validation and incorporate sample weights for imbalanced classes (many more negative examples than positive examples), we can't use weights with sklearn directly, so we do cross-validation manually.\n",
    "\n",
    "The [StratifiedKFold](https://sklearn.org/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) object can give us a set of k testing/training sets by using the `split()` method, which returns an iterator with the training/testing indices. This allows us to assemble all inputs (X and y, weights, labels, chromatin accessibility, etc.).\n",
    "\n",
    "The [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit) object also provides a split method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "LJ97tZwfk3MB",
    "outputId": "d33ca930-01c8-4a56-82b8-f8fe7aadc24b"
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "n_fold = 3\n",
    "include_chromatin_data = True\n",
    "\n",
    "# we can use either of these,\n",
    "# but we'll opt for shuffle\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=n_fold, \n",
    "                        shuffle=True, \n",
    "                        random_state=seed)\n",
    "\n",
    "shuffle = StratifiedShuffleSplit(n_splits=n_fold,\n",
    "                                 train_size = 0.7,\n",
    "                                 test_size = 0.3,\n",
    "                                 random_state = seed)\n",
    "\n",
    "models = []\n",
    "fithists = []\n",
    "\n",
    "for ifold, (train_ix, test_ix) in enumerate(shuffle.split(X,y)):\n",
    "    \n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    w_train, w_test = np.squeeze(w[train_ix]), np.squeeze(w[test_ix])\n",
    "    chrom_train, chrom_test = np.squeeze(chromatin[train_ix]), np.squeeze(chromatin[test_ix])\n",
    "    \n",
    "    print(\"Training on fold %d...\"%(ifold+1))\n",
    "    \n",
    "    \n",
    "    # if we use the chromatin model, we need a list of inputs\n",
    "    \n",
    "    if include_chromatin_data:\n",
    "        model = create_chromatin()\n",
    "        hist = model.fit([X_train,chrom_train], y_train,\n",
    "                         sample_weight = w_train,\n",
    "                         batch_size = 1000,\n",
    "                         epochs = n_epochs,\n",
    "                         verbose = 0,\n",
    "                         validation_data=([X_test,chrom_test],y_test,w_test))\n",
    "    else:\n",
    "        model = create_baseline()\n",
    "        hist = model.fit(X_train, y_train,\n",
    "                         sample_weight = w_train,\n",
    "                         batch_size = 1000,\n",
    "                         epochs = n_epochs,\n",
    "                         verbose = 0,\n",
    "                         validation_data=(X_test,y_test,w_test))\n",
    "\n",
    "    models.append(model)\n",
    "    fithists.append(hist)\n",
    "    \n",
    "    print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "-pVERzb-gr4q",
    "outputId": "5787af65-d618-42f6-ca0e-1f032121b499"
   },
   "outputs": [],
   "source": [
    "print(\"Model results (validation):\")\n",
    "print(\"\\n\")\n",
    "print(\"Loss (Mean):      %0.4f\"%(np.mean([h.history['val_loss'] for h in fithists])))\n",
    "print(\"Loss (Std):       %0.4f\"%(np.std([h.history['val_loss'] for h in fithists])))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy (Mean):  %0.2f%%\"%(100*np.mean([h.history['val_acc'] for h in fithists])))\n",
    "print(\"Accuracy (Std):   %0.2f%%\"%(100*np.std([h.history['val_acc'] for h in fithists])))\n",
    "print(\"\\n\")\n",
    "print(\"Precision (Mean): %0.2f%%\"%(100*np.mean([h.history['val_precision'] for h in fithists])))\n",
    "print(\"Precision (Std):  %0.2f%%\"%(100*np.std([h.history['val_precision'] for h in fithists])))\n",
    "print(\"\\n\")\n",
    "print(\"Recall (Mean):    %0.2f%%\"%(100*np.mean([h.history['val_recall'] for h in fithists])))\n",
    "print(\"Recall (Std):     %0.2f%%\"%(100*np.std([h.history['val_recall'] for h in fithists])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2cqF7SyFb_v7"
   },
   "outputs": [],
   "source": [
    "def loss_rate_plot(hist, ax, label='',legend=False):\n",
    "    ax.plot(hist.history['loss'])\n",
    "    ax.plot(hist.history['val_loss'])\n",
    "    if label=='':\n",
    "        ax.set_title(\"Loss Rate\", size=14)\n",
    "    else:\n",
    "        ax.set_title(\"Loss Rate (%s)\"%(label), size=14)\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_xlabel('Training interations')\n",
    "    if legend:\n",
    "        ax.legend(['Training', 'Validation'], loc='upper right')\n",
    "\n",
    "def accuracy_rate_plot(hist,ax,label='',legend=False):\n",
    "    ax.plot([j*100 for j in hist.history['acc']])\n",
    "    ax.plot([j*100 for j in hist.history['val_acc']])\n",
    "    if label=='':\n",
    "        ax.set_title(\"Accuracy\", size=14)\n",
    "    else:\n",
    "        ax.set_title(\"Accuracy (%s)\"%(label), size=14)\n",
    "    ax.set_ylabel('Accuracy %')\n",
    "    ax.set_xlabel('Training iterations')\n",
    "    if legend:\n",
    "        ax.legend(['Training','Validation'], loc='lower right')\n",
    "\n",
    "def precision_rate_plot(hist,ax,label='',legend=False):\n",
    "    ax.plot([j*100 for j in hist.history['precision']])\n",
    "    ax.plot([j*100 for j in hist.history['val_precision']])\n",
    "    if label=='':\n",
    "        ax.set_title(\"Precision\", size=14)\n",
    "    else:\n",
    "        ax.set_title(\"Precision (%s)\"%(label), size=14)\n",
    "    ax.set_ylabel('Precision %')\n",
    "    ax.set_xlabel('Training iterations')\n",
    "    if legend:\n",
    "        ax.legend(['Training','Validation'], loc='lower right')\n",
    "\n",
    "def recall_rate_plot(hist,ax,label='',legend=False):\n",
    "    ax.plot([j*100 for j in hist.history['recall']])\n",
    "    ax.plot([j*100 for j in hist.history['val_recall']])\n",
    "    if label=='':\n",
    "        ax.set_title(\"Recall\", size=14)\n",
    "    else:\n",
    "        ax.set_title(\"Recall (%s)\"%(label), size=14)\n",
    "    ax.set_ylabel('Recall %')\n",
    "    ax.set_xlabel('Training iterations')\n",
    "    if legend:\n",
    "        ax.legend(['Training','Validation'], loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1289
    },
    "colab_type": "code",
    "id": "EPdyOVmckA1y",
    "outputId": "e359511d-d081-4405-a2ba-63b0f9eb301d"
   },
   "outputs": [],
   "source": [
    "for i in range(shuffle.get_n_splits()):\n",
    "    \n",
    "    fig, [[ax1,ax2],[ax3,ax4]] = plt.subplots(2,2, figsize=(8,6))\n",
    "\n",
    "    loss_rate_plot(fithists[i], ax1, legend=True, label=\"Fold %d\"%(i+1))\n",
    "    accuracy_rate_plot(fithists[i], ax2, label=\"Fold %d\"%(i+1))\n",
    "    precision_rate_plot(fithists[i], ax3, label=\"Fold %d\"%(i+1))\n",
    "    recall_rate_plot(fithists[i], ax4, label=\"Fold %d\"%(i+1))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3ybleguoSSK"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else ','\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1118
    },
    "colab_type": "code",
    "id": "OdGe7D5xsbFz",
    "outputId": "0b3f1a2c-4821-451a-a330-6cbbb49cf14c"
   },
   "outputs": [],
   "source": [
    "for ifold, (train_ix, test_ix) in enumerate(shuffle.split(X,y)):\n",
    "\n",
    "    print(\"---------------\")\n",
    "    print(\"Fold %d:\"%(ifold+1))\n",
    "    \n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    w_train, w_test = np.squeeze(w[train_ix]), np.squeeze(w[test_ix])\n",
    "    chrom_train, chrom_test = chromatin[train_ix], chromatin[test_ix]\n",
    "    \n",
    "    model = models[ifold]\n",
    "    \n",
    "    if include_chromatin_data:\n",
    "        y_test_pred = model.predict([X_test,chrom_test])\n",
    "    else:\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "    y_test_pred = np.round(y_test_pred)\n",
    "\n",
    "    ax = plot_confusion_matrix(y_test, y_test_pred, ['0','1'], title=\"Confusion Matrix - Fold %d\"%(ifold+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cau62q_DDxUa"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YP-RN0vdtl6F"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred, weights):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)#, \n",
    "                            #sample_weight = weights)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc_score(y_true, y_pred))\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.plot([0,1],[0,1],'k--')\n",
    "    ax.set_title(\"ROC Curve\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyzIj1ah3Qpo"
   },
   "source": [
    "Finally, we compute the ROC curve for all k models from the k-fold cross-validation and use those curves to assemble the mean and variance of the ROC curve at every point. See [ROC with cross validation example](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html) in the sklearn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "id": "mjocReVJ-gQs",
    "outputId": "801c6e92-5392-475c-f8c2-71b7ac1365c1"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n",
    "\n",
    "from scipy import interp\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "\n",
    "for ifold, (train_ix, test_ix) in enumerate(shuffle.split(X,y)):\n",
    "\n",
    "    print(\"Working on fold %d...\"%(ifold+1))\n",
    "    \n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    w_train, w_test = np.squeeze(w[train_ix]), np.squeeze(w[test_ix])\n",
    "    chrom_train, chrom_test = chromatin[train_ix], chromatin[test_ix]\n",
    "    \n",
    "    model = models[ifold]\n",
    "    \n",
    "    if include_chromatin_data:\n",
    "        y_test_pred = model.predict([X_test,chrom_test]).ravel()\n",
    "    else:\n",
    "        y_test_pred = model.predict(X_test).ravel()\n",
    "        \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "    tprs.append(interp(mean_fpr,fpr,tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ax.plot(fpr,tpr, alpha=0.3)\n",
    "\n",
    "\n",
    "mean_tpr = np.mean(tprs,axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b', alpha=0.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.2)\n",
    "\n",
    "ax.plot([0,1],[0,1],'--k',lw=2)\n",
    "\n",
    "ax.set_title('ROC Curve, 1D CNN With Chromatin')\n",
    "\n",
    "print(\"Area under curve:\")\n",
    "print(\"Mean: %0.4f\"%(mean_auc))\n",
    "print(\"Std: %0.4f\"%(std_auc))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKUIyyXCunDO"
   },
   "source": [
    "## Class Weights\n",
    "\n",
    "Next we try replacing the weights that came with the data set with class weights. Let's review the imbalance in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Y94d4ZP0-s7E",
    "outputId": "af5fdf0d-d79f-4660-8ee4-747cb6d159d4"
   },
   "outputs": [],
   "source": [
    "neg = np.sum(y==0)\n",
    "pos = np.sum(y==1)\n",
    "print(\"Negative examples: %d\"%(neg))\n",
    "print(\"Positive examples: %d\"%(pos))\n",
    "print(\"Percent positive: %0.2f%%\"%(100*(pos/(pos+neg))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NvwWmXJVvREN"
   },
   "source": [
    "We can use the `class_weight` module from sklearn to automatically compute class weights, which can be passed to keras when we fit our model to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QgdwWlLSAvli",
    "outputId": "aef805ec-549d-4c6a-94b9-6bf4cf7bf7ac"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "labels = np.squeeze(y_train)\n",
    "\n",
    "weights = class_weight.compute_class_weight('balanced',classes,labels)\n",
    "\n",
    "class_weights = {}\n",
    "for c,w in zip(classes,weights):\n",
    "    class_weights[c] = w\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6vdHBlMfw6G7"
   },
   "source": [
    "Now we re-fit the model to data, this time using the class weights from sklearn instead of the weights provided in the data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "Iw7ZmHYIvOme",
    "outputId": "87585d0a-8b87-4163-f9aa-780b1eb81423"
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "n_fold = 3\n",
    "include_chromatin_data = True\n",
    "\n",
    "shuffle = StratifiedShuffleSplit(n_splits=n_fold,\n",
    "                                 train_size = 0.7,\n",
    "                                 test_size = 0.3,\n",
    "                                 random_state = seed)\n",
    "\n",
    "models2 = []\n",
    "fithists2 = []\n",
    "\n",
    "for ifold, (train_ix, test_ix) in enumerate(shuffle.split(X,y)):\n",
    "    \n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    chrom_train, chrom_test = np.squeeze(chromatin[train_ix]), np.squeeze(chromatin[test_ix])\n",
    "    \n",
    "    print(\"Training on fold %d...\"%(ifold+1))\n",
    "    \n",
    "    model = create_chromatin()\n",
    "    hist = model.fit([X_train,chrom_train], y_train,\n",
    "                     class_weight = class_weights,\n",
    "                     batch_size = 1000,\n",
    "                     epochs = n_epochs,\n",
    "                     verbose = 0,\n",
    "                     validation_data=([X_test,chrom_test],y_test))\n",
    "    \n",
    "    models2.append(model)\n",
    "    fithists2.append(hist)\n",
    "    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1289
    },
    "colab_type": "code",
    "id": "9roqLPVfxUNq",
    "outputId": "1bab0d2c-42ca-46eb-d25a-45031de98ca0"
   },
   "outputs": [],
   "source": [
    "for i in range(shuffle.get_n_splits()):\n",
    "    \n",
    "    fig, [[ax1,ax2],[ax3,ax4]] = plt.subplots(2,2, figsize=(8,6))\n",
    "\n",
    "    loss_rate_plot(fithists2[i], ax1, legend=True, label=\"Fold %d\"%(i+1))\n",
    "    accuracy_rate_plot(fithists2[i], ax2, label=\"Fold %d\"%(i+1))\n",
    "    precision_rate_plot(fithists2[i], ax3, label=\"Fold %d\"%(i+1))\n",
    "    recall_rate_plot(fithists2[i], ax4, label=\"Fold %d\"%(i+1))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1118
    },
    "colab_type": "code",
    "id": "kmrzl7QGyCgy",
    "outputId": "e821f331-c8ec-480c-e8a5-fe698fbf7a3c"
   },
   "outputs": [],
   "source": [
    "for ifold, (train_ix, test_ix) in enumerate(shuffle.split(X,y)):\n",
    "\n",
    "    print(\"---------------\")\n",
    "    print(\"Fold %d:\"%(ifold+1))\n",
    "    \n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    chrom_train, chrom_test = chromatin[train_ix], chromatin[test_ix]\n",
    "    \n",
    "    model = models2[ifold]\n",
    "    \n",
    "    y_test_pred = model.predict([X_test,chrom_test])\n",
    "    \n",
    "    y_test_pred = np.round(y_test_pred)\n",
    "\n",
    "    ax = plot_confusion_matrix(y_test, y_test_pred, ['0','1'], title=\"Confusion Matrix - Fold %d\\n(Class-Weighted Samples)\"%(ifold+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPy00XRO343w"
   },
   "source": [
    "The code below is similar to, but slightly modified from, the ROC plot above. It shows the same quantity: the ROC curves for all k models from the k-fold cross-validation, and the mean and standard deviation assembled from those models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "colab_type": "code",
    "id": "Dldz0ftNyfPs",
    "outputId": "bd2668df-1dd0-4da9-b6e1-62738a33c9e9"
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n",
    "\n",
    "from scipy import interp\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,8))\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0,1,100)\n",
    "\n",
    "for ifold, (train_ix, test_ix) in enumerate(shuffle.split(X,y)):\n",
    "\n",
    "    print(\"Working on fold %d...\"%(ifold+1))\n",
    "    \n",
    "    X_train, X_test = X[train_ix], X[test_ix]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    chrom_train, chrom_test = chromatin[train_ix], chromatin[test_ix]\n",
    "    \n",
    "    model = models2[ifold]\n",
    "    \n",
    "    y_test_pred = model.predict([X_test,chrom_test]).ravel()\n",
    "        \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred)\n",
    "    tprs.append(interp(mean_fpr,fpr,tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ax.plot(fpr,tpr, alpha=0.3)\n",
    "\n",
    "    \n",
    "mean_tpr = np.mean(tprs,axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b', alpha=0.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.2)\n",
    "\n",
    "ax.plot([0,1],[0,1],'--k',lw=2)\n",
    "\n",
    "ax.set_title('ROC Curve, 1D CNN With Chromatin\\n(Class-Weighted Samples)')\n",
    "\n",
    "print(\"Area under curve:\")\n",
    "print(\"Mean: %0.4f\"%(mean_auc))\n",
    "print(\"Std: %0.4f\"%(std_auc))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NIhFp4KS4Ob7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ray_tune_cnn1d_dna_transcription.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
